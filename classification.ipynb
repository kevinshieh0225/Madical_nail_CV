{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "import PIL\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Conv2d, MaxPool2d, Module\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from ipywidgets import IntProgress\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, x, y, transform):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.x[idx], cv2.IMREAD_COLOR)\n",
    "        if img is None:\n",
    "            print('fuck')\n",
    "            print(self.x[idx])\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img)\n",
    "        return img, self.y[idx]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nail_csv(folder='./ML_hw2/學生的training_data/'):\n",
    "    path = []\n",
    "    label = []\n",
    "    # 此時我需要的輸出格式為：\n",
    "    # path: 照片路徑 : ./ML_hw2/學生的training_data/A/id\n",
    "    # label: 標籤  : [1,0,0]\n",
    "    slice_csv = re.sub('學生的', \"\" ,folder.split('/')[-2] ) #提取training_data或test_data\n",
    "    csv_path = f'{folder}{slice_csv}.csv'\n",
    "    with open(csv_path, 'r', encoding='utf8') as f:        \n",
    "        f.readline()\n",
    "        for line in f:\n",
    "            clean_line = line.replace('\\n', '').replace('\\ufeff', '').split(',')\n",
    "            # [id, light, ground_truth, grade]\n",
    "            curr_img_path = f'{folder}{clean_line[1]}/{clean_line[0]}'\n",
    "            if not os.path.isfile(curr_img_path):\n",
    "                print('catch')\n",
    "                continue\n",
    "            \"\"\"\n",
    "            img = cv2.imread(curr_img_path, cv2.IMREAD_COLOR)\n",
    "            if img is None:\n",
    "                print(curr_img_path)\n",
    "                continue\n",
    "            \"\"\"\n",
    "            \n",
    "            path.append(curr_img_path)\n",
    "            label.append(int(clean_line[3])-1)\n",
    "    print('data size: ')\n",
    "    print(len(path), len(label))\n",
    "    print(path[:10])\n",
    "    print(label[:10])\n",
    "    count = np.zeros(3)\n",
    "    for check in label:\n",
    "      count[int(check)] += 1\n",
    "    print('(1)：'+str(count[0])+' '+str(count[0]/len(label)))\n",
    "    print('(2)：'+str(count[1])+' '+str(count[1]/len(label)))\n",
    "    print('(3)：'+str(count[2])+' '+str(count[2]/len(label)))\n",
    "\n",
    "    print()\n",
    "    return path, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_prepare(folder='./ML_hw2/學生的training_data/', batch_size=8):\n",
    "    \"\"\"\n",
    "    aug:\n",
    "        folder:讀入資料之位置\n",
    "    \"\"\"\n",
    "    transform_flip = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((224,224)),\n",
    "        torchvision.transforms.RandomHorizontalFlip(p = 1),\n",
    "        torchvision.transforms.RandomRotation(15, resample=PIL.Image.BILINEAR),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        ])\n",
    "\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((224,224)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        ])\n",
    "\n",
    "    transform_rotation = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((224,224)),\n",
    "        torchvision.transforms.RandomRotation((10,15), resample=PIL.Image.BILINEAR),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        ])\n",
    "\n",
    "    path, label = load_nail_csv(folder)\n",
    "    \n",
    "    l = []\n",
    "    l.append(Dataset(path, label, transform_flip))\n",
    "    l.append(Dataset(path, label, transform))\n",
    "    l.append(Dataset(path, label, transform_rotation))\n",
    "    augment_dataset = torch.utils.data.ConcatDataset(l)\n",
    "    #augment_dataset = Dataset(path, label, transform_flip) + Dataset(path, label, transform) + Dataset(path, label, transform_rotation)\n",
    "    print(f'augment data len : {len(augment_dataset)}')\n",
    "    print(f'augment data type : {augment_dataset}')\n",
    "    #切分70%當作訓練集、30%當作驗證集\n",
    "    train_size = int(0.7 * len(augment_dataset))\n",
    "    valid_size = len(augment_dataset) - train_size\n",
    "    train_data, valid_data = torch.utils.data.random_split(augment_dataset, [train_size, valid_size])\n",
    "    print(train_data)\n",
    "    print(f'augment data len : {len(train_data)}')\n",
    "    print(f'augment data type : {train_data}')\n",
    "    \n",
    "    print(valid_data)\n",
    "    print(f'augment data len : {len(valid_data)}')\n",
    "    print(f'augment data type : {valid_data}')\n",
    "    \n",
    "    train_dataloader = DataLoader( train_data , batch_size=batch_size, shuffle=True)\n",
    "    valid_dataloader = DataLoader( valid_data , batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    \n",
    "    print(train_data)\n",
    "    print(f'augment data len : {len(train_dataloader)}')\n",
    "    print(f'augment data type : {train_dataloader}')\n",
    "    \n",
    "    print(valid_data)\n",
    "    print(f'augment data len : {len(valid_dataloader)}')\n",
    "    print(f'augment data type : {valid_dataloader}')\n",
    "    \n",
    "    return train_dataloader, valid_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU State: cuda:0\n",
      "CNN_Model(\n",
      "  (CNN): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 8, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=22472, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=3, bias=True)\n",
      "    (3): LogSoftmax()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "    #列出需要哪些層\n",
    "    def __init__(self):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        self.CNN = nn.Sequential(                       #(3,224,224)\n",
    "            nn.Conv2d(3, 16, kernel_size=5, stride=1),  #(16,220,220)\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Max pool 1\n",
    "            nn.MaxPool2d(kernel_size=2),                #(16,110,110)\n",
    "            # Convolution 2\n",
    "            nn.Conv2d(16,8, kernel_size=5, stride=1),  #(8,106,106)\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Max pool 2\n",
    "            nn.MaxPool2d(kernel_size=2)                 #(8,53,53)\n",
    "            # Fully connected 1 ,#input_shape=(8*53*53)\n",
    "        )\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(in_features=8*53*53, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=3),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.CNN(input)\n",
    "        out = out.view(out.size(0), -1) \n",
    "        return self.main(out)\n",
    "   \n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('GPU State:', device)\n",
    "net = CNN_Model().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,n_epochs,train_loader,valid_loader,optimizer,criterion,batch_size):\n",
    "    train_acc_his,valid_acc_his=[],[]\n",
    "    train_losses_his,valid_losses_his=[],[]\n",
    "    model.cuda()\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # keep track of training and validation loss\n",
    "        train_loss,valid_loss = 0.0,0.0\n",
    "        train_losses,valid_losses=[],[]\n",
    "        train_correct,val_correct,train_total,val_total=0,0,0,0\n",
    "        train_pred,train_target=torch.zeros(batch_size,1),torch.zeros(batch_size,1)\n",
    "        val_pred,val_target=torch.zeros(batch_size,1),torch.zeros(batch_size,1)\n",
    "        count=0\n",
    "        count2=0\n",
    "        print('running epoch: {}'.format(epoch))\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for data, target in tqdm(train_loader):\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            if True:#train_on_gpu\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            #calculate accuracy\n",
    "            pred = output.data.max(dim = 1, keepdim = True)[1]\n",
    "            train_correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "            train_total += data.size(0)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update training loss\n",
    "            train_losses.append(loss.item()*data.size(0))\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            if count==0:\n",
    "                train_pred=pred\n",
    "                train_target=target.data.view_as(pred)\n",
    "                count=count+1\n",
    "            else:\n",
    "                train_pred=torch.cat((train_pred,pred), 0)\n",
    "                train_target=torch.cat((train_target,target.data.view_as(pred)), 0)\n",
    "        train_pred=train_pred.cpu().view(-1).numpy().tolist()\n",
    "        train_target=train_target.cpu().view(-1).numpy().tolist()\n",
    "######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for data, target in tqdm(valid_loader):\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            if True:#train_on_gpu\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss =criterion(output, target)\n",
    "            #calculate accuracy\n",
    "            pred = output.data.max(dim = 1, keepdim = True)[1]\n",
    "            val_correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "            val_total += data.size(0)\n",
    "            valid_losses.append(loss.item()*data.size(0))\n",
    "            if count2==0:\n",
    "                val_pred=pred\n",
    "                val_target=target.data.view_as(pred)\n",
    "                count2=count+1\n",
    "            else:\n",
    "                val_pred=torch.cat((val_pred,pred), 0)\n",
    "                val_target=torch.cat((val_target,target.data.view_as(pred)), 0)\n",
    "        val_pred=val_pred.cpu().view(-1).numpy().tolist()\n",
    "        val_target=val_target.cpu().view(-1).numpy().tolist()\n",
    "        \n",
    "        # calculate average losses\n",
    "        train_loss=np.average(train_losses)\n",
    "        valid_loss=np.average(valid_losses)\n",
    "        \n",
    "        # calculate average accuracy\n",
    "        train_acc=train_correct/train_total\n",
    "        valid_acc=val_correct/val_total\n",
    "        train_acc_his.append(train_acc)\n",
    "        valid_acc_his.append(valid_acc)\n",
    "        train_losses_his.append(train_loss)\n",
    "        valid_losses_his.append(valid_loss)\n",
    "# print training/validation statistics \n",
    "        print(f'\\tTraining Loss: {train_loss:.6f} \\tValidation Loss: {valid_loss:.6f}')\n",
    "        print(f'\\tTraining Accuracy: {train_acc:.6f} \\tValidation Accuracy: {valid_acc:.6f}')\n",
    "    return train_acc_his,valid_acc_his,train_losses_his,valid_losses_his,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU State: cuda:1\n",
      "catch\n",
      "catch\n",
      "data size: \n",
      "2026 2026\n",
      "['./ML_hw2/學生的training_data/A/00130747_A_3457_20200715_100727_7.5.jpg', './ML_hw2/學生的training_data/A/00130747_A_3458_20200715_100736_7.5.jpg', './ML_hw2/學生的training_data/A/00130747_A_4810_20200812_112534_7.9.jpg', './ML_hw2/學生的training_data/A/00130747_A_4811_20200812_112539_7.9.jpg', './ML_hw2/學生的training_data/A/00241567_A_6659_20200916_153156_7.6.jpg', './ML_hw2/學生的training_data/A/00241567_A_6660_20200916_153202_7.6.jpg', './ML_hw2/學生的training_data/A/00241567_A_7643_20200930_104310_7.8.jpg', './ML_hw2/學生的training_data/A/00241567_A_7644_20200930_104313_7.8.jpg', './ML_hw2/學生的training_data/A/00311620_A_3097_20200710_102137_13.5.jpg', './ML_hw2/學生的training_data/A/00311620_A_3098_20200710_102142_13.5.jpg']\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 2, 2]\n",
      "(1)：377.0 0.18608094768015795\n",
      "(2)：488.0 0.24086870681145114\n",
      "(3)：1161.0 0.573050345508391\n",
      "\n",
      "augment data len : 6078\n",
      "augment data type : <torch.utils.data.dataset.ConcatDataset object at 0x7fdf1027a908>\n",
      "<torch.utils.data.dataset.Subset object at 0x7fdf1027aa58>\n",
      "augment data len : 4254\n",
      "augment data type : <torch.utils.data.dataset.Subset object at 0x7fdf1027aa58>\n",
      "<torch.utils.data.dataset.Subset object at 0x7fdf1027aa90>\n",
      "augment data len : 1824\n",
      "augment data type : <torch.utils.data.dataset.Subset object at 0x7fdf1027aa90>\n",
      "<torch.utils.data.dataset.Subset object at 0x7fdf1027aa58>\n",
      "augment data len : 133\n",
      "augment data type : <torch.utils.data.dataloader.DataLoader object at 0x7fdf1027a8d0>\n",
      "<torch.utils.data.dataset.Subset object at 0x7fdf1027aa90>\n",
      "augment data len : 57\n",
      "augment data type : <torch.utils.data.dataloader.DataLoader object at 0x7fdf1027ab00>\n",
      "running epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842c63ca777844b6b0beef6df7e1487d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=133.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4302383defa944ce8d3783388226406c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "print('GPU State:', device)\n",
    "model1=CNN_Model()\n",
    "n_epochs = 10\n",
    "LR = 0.0001\n",
    "batch_size = 32\n",
    "train_dataloader, valid_dataloader = dataloader_prepare(folder='./ML_hw2/學生的training_data/',batch_size = 32)\n",
    "optimizer1 = torch.optim.Adam(model1.parameters(), lr=LR)\n",
    "criterion = CrossEntropyLoss()\n",
    "train_acc_his,valid_acc_his,train_losses_his,valid_losses_his,model1=train(model1,n_epochs,train_dataloader,valid_dataloader,optimizer1,criterion, batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
