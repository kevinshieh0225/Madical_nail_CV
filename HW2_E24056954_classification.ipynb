{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU State: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "import PIL\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Conv2d, MaxPool2d, Module\n",
    "from torch.optim import Adam\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "from ipywidgets import IntProgress\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('GPU State:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, x, y, transform):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.x[idx], cv2.IMREAD_COLOR)\n",
    "        if img is None:\n",
    "            print('Not found img : ', self.x[idx])\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img)\n",
    "        return img, self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nail_csv(folder='./ML_hw2/學生的training_data/'):\n",
    "    \"\"\"\n",
    "    intro:\n",
    "        先存入原圖位置，壓縮照片後再存入./ML_hw2/學生的training_data/resize/\n",
    "        回傳 path , label\n",
    "    aug:\n",
    "        folder = 讀入資料之目的資料夾\n",
    "        batch_size = batch_size\n",
    "    output:\n",
    "        path: 照片路徑 : ./ML_hw2/resize/id\n",
    "        label: 標籤  : int x={0,1,2} array\n",
    "    \"\"\"\n",
    "    path = []\n",
    "    label = []\n",
    "    slice_csv = re.sub('學生的', \"\" ,folder.split('/')[-2] ) #提取training_data或test_data\n",
    "    csv_path = f'{folder}{slice_csv}.csv'\n",
    "    resize_folder = f'{folder}resize/'\n",
    "    if not os.path.isdir(resize_folder):\n",
    "        os.makedirs(resize_folder)\n",
    "    with open(csv_path, 'r', encoding='utf8') as f:        \n",
    "        f.readline()\n",
    "        for line in tqdm(f):\n",
    "            clean_line = line.replace('\\n', '').replace('\\ufeff', '').split(',')\n",
    "            # [id, light, ground_truth, grade]\n",
    "            curr_img_path = f'{folder}{clean_line[1]}/{clean_line[0]}'\n",
    "            new_img_path = f'{resize_folder}{clean_line[0]}'\n",
    "            if not os.path.isfile(curr_img_path):\n",
    "                print(f'No file for path : {curr_img_path}')\n",
    "                continue\n",
    "            #將未處理照片存入新資料夾位置：./ML_hw2/resize/\n",
    "            if not os.path.isfile(new_img_path):\n",
    "                img = cv2.imread(curr_img_path, cv2.IMREAD_COLOR)\n",
    "                img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "                cv2.imwrite(new_img_path, img)\n",
    "            path.append(new_img_path)\n",
    "            label.append(int(clean_line[3])-1)\n",
    "\n",
    "    print('data size: ')\n",
    "    print(len(path), len(label))\n",
    "    count = np.zeros(3)\n",
    "    for check in label:\n",
    "        count[int(check)] += 1\n",
    "    print('(1)：'+str(count[0])+' '+str(count[0]/len(label)))\n",
    "    print('(2)：'+str(count[1])+' '+str(count[1]/len(label)))\n",
    "    print('(3)：'+str(count[2])+' '+str(count[2]/len(label)))\n",
    "\n",
    "    print()\n",
    "    return path, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_prepare(folder='./ML_hw2/學生的training_data/', batch_size=8):\n",
    "    \"\"\"\n",
    "    intro:\n",
    "        使用load_nail_csv準備照片\n",
    "        Dataset轉為dataset型式\n",
    "        切 train, validation set , DataLoader存入\n",
    "    aug:\n",
    "        folder = 讀入資料之目的資料夾\n",
    "        batch_size = batch_size\n",
    "    output:\n",
    "        train_dataloader, valid_dataloader\n",
    "    \"\"\"\n",
    "\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        #torchvision.transforms.Resize((224,224)),\n",
    "        torchvision.transforms.RandomHorizontalFlip(p = 0.5),\n",
    "        torchvision.transforms.RandomRotation(15, resample=PIL.Image.BILINEAR),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        ])\n",
    "\n",
    "    path, label = load_nail_csv(folder)\n",
    "    augment_dataset = Dataset(path, label, transform)\n",
    "    \n",
    "    #切分70%當作訓練集、30%當作驗證集\n",
    "    train_size = int(0.7 * len(augment_dataset))\n",
    "    valid_size = len(augment_dataset) - train_size\n",
    "    train_data, valid_data = torch.utils.data.random_split(augment_dataset, [train_size, valid_size])\n",
    "    \n",
    "    train_dataloader = DataLoader( train_data , batch_size=batch_size, shuffle=True)\n",
    "    valid_dataloader = DataLoader( valid_data , batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return train_dataloader, valid_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,name,n_epochs,train_loader,valid_loader,optimizer,criterion,batch_size,patience):\n",
    "    \"\"\"\n",
    "    intro:\n",
    "        每次epoch都 train the model , validate the model\n",
    "        並計算Early Stopping\n",
    "        印出 train_loss , train_acc , val_loss , val_acc\n",
    "        回傳 model\n",
    "    aug:\n",
    "        model,n_epochs,train_loader,valid_loader,optimizer,criterion,batch_size\n",
    "    output:\n",
    "        model\n",
    "    \"\"\"\n",
    "    if os.path.isfile(f'./hw2_classification_weight_{name}.pt'):\n",
    "        print(f'keep finetune{name}')\n",
    "        model = torch.load(f'./hw2_classification_weight_{name}.pt')\n",
    "    \n",
    "    best_train_loss = 100\n",
    "    best_train_acc = 0\n",
    "    best_val_loss = 100\n",
    "    best_val_acc = 0\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    else:\n",
    "        print('no gpu use')\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # keep track of training and validation loss\n",
    "        train_loss,valid_loss = 0.0,0.0\n",
    "        train_losses,valid_losses=[],[]\n",
    "        train_correct,val_correct,train_total,val_total=0,0,0,0\n",
    "\n",
    "        print('running epoch: {}'.format(epoch))\n",
    "        #############################################################################################################\n",
    "        #                                              train the model                                              #\n",
    "        #############################################################################################################\n",
    "        model.train()\n",
    "        for data, target in train_loader:\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            if torch.cuda.is_available():#train_on_gpu\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            else:\n",
    "                print('1')\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            #calculate accuracy\n",
    "            pred = output.data.max(dim = 1, keepdim = True)[1]\n",
    "            train_correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "            train_total += data.size(0)\n",
    "            \n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update training loss\n",
    "            train_losses.append(loss.item()*data.size(0))\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        #############################################################################################################\n",
    "        #                                            validate the model                                             #\n",
    "        #############################################################################################################\n",
    "        model.eval()\n",
    "        for data, target in valid_loader:\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            if torch.cuda.is_available():#train_on_gpu\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "                \n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss =criterion(output, target)\n",
    "            #calculate accuracy\n",
    "            pred = output.data.max(dim = 1, keepdim = True)[1]\n",
    "            val_correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "            val_total += data.size(0)\n",
    "            # update validation loss\n",
    "            valid_losses.append(loss.item()*data.size(0))\n",
    "        \n",
    "        \n",
    "        #############################################################################################################\n",
    "        #                                        print train/val epoch result                                       #\n",
    "        #############################################################################################################\n",
    "        # calculate average losses\n",
    "        train_loss=np.average(train_losses)\n",
    "        valid_loss=np.average(valid_losses)\n",
    "        # calculate average accuracy\n",
    "        train_acc=train_correct/train_total\n",
    "        valid_acc=val_correct/val_total\n",
    "        print(f'\\tTraining Loss: {train_loss:.3f} \\tValidation Loss: {valid_loss:.3f}')\n",
    "        print(f'\\tTraining Accuracy: {train_acc:.3f} \\tValidation Accuracy: {valid_acc:.3f}')\n",
    "        \n",
    "        #############################################################################################################\n",
    "        #                                              Early Stopping                                               #\n",
    "        #############################################################################################################\n",
    "        if valid_loss > best_val_loss:\n",
    "            trigger_times += 1\n",
    "            print(f'trigger times: {trigger_times}\\n')\n",
    "            if trigger_times > patience:\n",
    "                print(f'Early stopping at trigger times: {trigger_times}')\n",
    "                print(f'\\tLeast Training Loss: {best_train_loss:.4f} \\nLeast Validation Loss: {best_val_loss:.4f}')\n",
    "                print(f'\\tBest Training Accuracy: {best_train_acc:.4f} \\nBest Validation Accuracy: {best_val_acc:.4f}')\n",
    "                break\n",
    "        else:\n",
    "            trigger_times = 0\n",
    "            torch.save(model, f'./hw2_classification_weight_{name}.pt')\n",
    "            best_train_loss = train_loss\n",
    "            best_train_acc = train_acc\n",
    "            best_val_loss = valid_loss\n",
    "            best_val_acc = valid_acc\n",
    "            \n",
    "    model = torch.load(f'./hw2_classification_weight_{name}.pt')    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_result(model): \n",
    "    \"\"\"\n",
    "    intro:\n",
    "        讀取'./ML_hw2/學生的testing_data/'\n",
    "        並將照片處理，拿原本模型預測後輸出文件\n",
    "    aug:\n",
    "        model\n",
    "    result:\n",
    "        ./HW2_E24056954.csv\n",
    "    \"\"\"\n",
    "    #############################################################################################################\n",
    "    #                                   loading and resize testing picture                                      #\n",
    "    #############################################################################################################\n",
    "    testing_path = []\n",
    "    testing_write = []\n",
    "    folder = './ML_hw2/學生的testing_data/'\n",
    "    slice_csv = 'testing_data'#提取testing_data\n",
    "    csv_path = f'{folder}{slice_csv}.csv'\n",
    "    resize_folder = f'{folder}resize/'\n",
    "    if not os.path.isdir(resize_folder):\n",
    "        os.makedirs(resize_folder)\n",
    "    with open(csv_path, 'r', encoding='utf8') as f:   \n",
    "        testing_write.append(f.readline())\n",
    "        for line in f:\n",
    "            clean_line = line.replace('\\n', '').replace('\\ufeff', '').split(',')\n",
    "            # [id, light, ground_truth, grade]\n",
    "            testing_write.append(clean_line)\n",
    "            curr_img_path = f'{folder}{slice_csv}/{clean_line[0]}'\n",
    "            new_img_path = f'{resize_folder}{clean_line[0]}'\n",
    "            if not os.path.isfile(curr_img_path):\n",
    "                print(curr_img_path)\n",
    "                print('catch')\n",
    "                continue\n",
    "            if not os.path.isfile(new_img_path):\n",
    "                img = cv2.imread(curr_img_path, cv2.IMREAD_COLOR)\n",
    "                img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "                cv2.imwrite(new_img_path, img)\n",
    "            testing_path.append(new_img_path)\n",
    "    print('data size: ')\n",
    "    print(f'testing數量：{len(testing_path)}')\n",
    "    \n",
    "    #############################################################################################################\n",
    "    #                                   use hypothesis model predict testing set                                #\n",
    "    #############################################################################################################\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        ])\n",
    "    model.eval()\n",
    "    pred_label=[]\n",
    "    for path in tqdm(testing_path):\n",
    "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "        img = transform(img).cuda()\n",
    "        img = img.unsqueeze(0)\n",
    "        with torch.no_grad(): \n",
    "            output=model(img)\n",
    "        pred = output.data.max(dim = 1, keepdim = True)[1]\n",
    "        pred_label.append(int(pred))\n",
    "        print(f'{path} / {int(pred)}')\n",
    "    #############################################################################################################\n",
    "    #                                             output require csv                                            #\n",
    "    #############################################################################################################\n",
    "    with open('HW2_E24056954.csv', 'w', encoding='utf8') as wp:\n",
    "        wp.write(testing_write[0])\n",
    "        for pred_label_,testing_write_ in zip(pred_label,testing_write[1:]):\n",
    "            wp.write(f'{testing_write_[0]},{testing_write_[1]},,{pred_label_+1}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try alexnet finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ft_alexnet = models.alexnet(pretrained=True)\n",
    "# num_ftrs = model_ft_alexnet.classifier[6].in_features\n",
    "# model_ft_alexnet.classifier[6] = nn.Linear(num_ftrs,3)\n",
    "# model_ft_alexnet=model_ft_alexnet.to(device)# 放入裝置\n",
    "# print(model_ft_alexnet) # 列印新模型\n",
    "\n",
    "# n_epochs = 100\n",
    "# batch_size = 32\n",
    "# train_dataloader, valid_dataloader = dataloader_prepare(folder='./ML_hw2/學生的training_data/',batch_size = batch_size)\n",
    "# optimizer = torch.optim.Adam([\n",
    "#     {'params':model_ft_alexnet.parameters()}\n",
    "# ], lr=0.00001)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# patience = 3\n",
    "\n",
    "# model_ft_alexnet=train(model_ft_alexnet,'model_ft_wide_resnet50_2',n_epochs,train_dataloader,valid_dataloader,optimizer,criterion, batch_size , patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try wide_resnet50_2 finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft_wide_resnet50_2 = models.wide_resnet50_2(pretrained=True)\n",
    "num_ftrs = model_ft_wide_resnet50_2.fc.in_features\n",
    "model_ft_wide_resnet50_2.fc = nn.Linear(num_ftrs,3)\n",
    "model_ft_wide_resnet50_2=model_ft_wide_resnet50_2.to(device)# 放入裝置\n",
    "print(model_ft_wide_resnet50_2) # 列印新模型\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 32\n",
    "train_dataloader, valid_dataloader = dataloader_prepare(folder='./ML_hw2/學生的training_data/',batch_size = batch_size)\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params':model_ft_wide_resnet50_2.parameters()}\n",
    "], lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "patience = 3\n",
    "\n",
    "model_ft_wide_resnet50_2=train(model_ft_wide_resnet50_2,'model_ft_wide_resnet50_2',n_epochs,train_dataloader,valid_dataloader,optimizer,criterion, batch_size , patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try vgg19 finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ft_vgg19 = models.vgg19(pretrained=True)\n",
    "# num_ftrs = model_ft_vgg19.classifier[6].in_features\n",
    "# model_ft_vgg19.classifier[6] = nn.Linear(num_ftrs,3)\n",
    "# model_ft_vgg19=model_ft_vgg19.to(device)# 放入裝置\n",
    "# print(model_ft_vgg19) # 列印新模型\n",
    "\n",
    "# n_epochs = 100\n",
    "# batch_size = 32\n",
    "# train_dataloader, valid_dataloader = dataloader_prepare(folder='./ML_hw2/學生的training_data/',batch_size = batch_size)\n",
    "# optimizer = torch.optim.Adam([\n",
    "#     {'params':model_ft_vgg19.parameters()}\n",
    "# ], lr=0.0001)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# patience = 3\n",
    "\n",
    "# model_ft_vgg19=train(model_ft_vgg19,'model_ft_vgg19',n_epochs,train_dataloader,valid_dataloader,optimizer,criterion, batch_size , patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print testing data result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'model_ft_wide_resnet50_2'\n",
    "model_ft_wide_resnet50_2 = torch.load(f'./hw2_classification_weight_{name}.pt')  \n",
    "testing_result(model_ft_wide_resnet50_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test CNN + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (5): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (6): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (7): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_cnn = torch.load('./hw2_classification_weight_model_ft_wide_resnet50_2.pt')\n",
    "model_cnn_extractor = nn.Sequential(*list(model_cnn.children())[:-1]) # strips off last linear layer\n",
    "print(model_cnn_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "def trainsform_data( address_set , transform , model):\n",
    "    data = []\n",
    "    for add in tqdm(address_set):\n",
    "        img = cv2.imread(add, cv2.IMREAD_COLOR)\n",
    "        img = transform(img).cuda()\n",
    "        img = img.unsqueeze(0)\n",
    "        with torch.no_grad(): \n",
    "            output=model(img)\n",
    "        output = output.squeeze(0).squeeze(1).squeeze(1).tolist()\n",
    "        data.append(output)\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0214c2db59334a228fe7b4ca55745e62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No file for path : ./ML_hw2/學生的training_data/B/17871372_B_2514_20200703_094952_9.9.jpg\n",
      "No file for path : ./ML_hw2/學生的training_data/B/17871372_B_7322_20200925_114302_8.8.jpg\n",
      "\n",
      "data size: \n",
      "2026 2026\n",
      "(1)：377.0 0.18608094768015795\n",
      "(2)：488.0 0.24086870681145114\n",
      "(3)：1161.0 0.573050345508391\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7afa329b00c7403e8cc99e0a7d2f928a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1620.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce2030563b6495b9c07674626747963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=406.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_X len:1620\n",
      "train_y len:1620\n",
      "test_X len:406\n",
      "test_y len:406\n",
      "train_X type:<class 'pandas.core.frame.DataFrame'>\n",
      "train_y type:<class 'pandas.core.frame.DataFrame'>\n",
      "test_X type:<class 'pandas.core.frame.DataFrame'>\n",
      "test_y type:<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "add_x , label_y = load_nail_csv(folder='./ML_hw2/學生的training_data/')\n",
    "train_add_x , test_add_x , train_y , test_y = train_test_split(add_x,label_y,test_size=0.2,random_state=0)\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "train_X = trainsform_data( train_add_x , transform , model_cnn_extractor)\n",
    "test_X = trainsform_data( test_add_x , transform , model_cnn_extractor)\n",
    "train_y = pd.DataFrame(train_y)\n",
    "test_y = pd.DataFrame(test_y)\n",
    "print(f'train_X len:{len(train_X)}')\n",
    "print(f'train_y len:{len(train_y)}')\n",
    "print(f'test_X len:{len(test_X)}')\n",
    "print(f'test_y len:{len(test_y)}')\n",
    "\n",
    "print(f'train_X type:{type(train_X)}')\n",
    "print(f'train_y type:{type(train_y)}')\n",
    "print(f'test_X type:{type(test_X)}')\n",
    "print(f'test_y type:{type(test_y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "\n",
    "# Instantiation \n",
    "xgb = XGBClassifier(\n",
    "        #樹的個數\n",
    "        n_estimators=100,\n",
    "        # 如同學習率\n",
    "        learning_rate= 0.3, \n",
    "        # 構建樹的深度，越大越容易過擬合    \n",
    "        max_depth=6, \n",
    "        # 隨機取樣訓練樣本 訓練例項的子取樣比\n",
    "        subsample=1)\n",
    "\n",
    "# Fitting the model \n",
    "xgb.fit(train_X, train_y) \n",
    "  \n",
    "# Predict the model \n",
    "pred = xgb.predict(test_X) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating test data...\n",
      "[[ 76   9   2]\n",
      " [  3  78   2]\n",
      " [  1   0 235]]\n",
      "accuracy_score\t0.958128078817734\n",
      "f1_score\t0.9391001279175395\n",
      "precision_score\t0.9432717741547636\n",
      "recall_score\t0.9363616554665967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "print('evaluating test data...')\n",
    "cm = confusion_matrix(test_y, pred)\n",
    "acc = accuracy_score(test_y, pred)\n",
    "f1 = f1_score(test_y, pred , average='macro')\n",
    "p = precision_score(test_y, pred, average='macro')\n",
    "r = recall_score(test_y, pred ,  average='macro')\n",
    "\n",
    "print(cm)\n",
    "print(f'accuracy_score\\t{acc}')\n",
    "print(f'f1_score\\t{f1}')\n",
    "print(f'precision_score\\t{p}')\n",
    "print(f'recall_score\\t{r}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
