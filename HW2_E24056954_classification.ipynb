{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "import PIL\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Conv2d, MaxPool2d, Module\n",
    "from torch.optim import Adam\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "from ipywidgets import IntProgress\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('GPU State:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, x, y, transform):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.x[idx], cv2.IMREAD_COLOR)\n",
    "        if img is None:\n",
    "            print('Not found img : ', self.x[idx])\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img)\n",
    "        return img, self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nail_csv(folder='./ML_hw2/學生的training_data/'):\n",
    "    \"\"\"\n",
    "    intro:\n",
    "        先存入原圖位置，壓縮照片後再存入./ML_hw2/學生的training_data/resize/\n",
    "        回傳 path , label\n",
    "    aug:\n",
    "        folder = 讀入資料之目的資料夾\n",
    "        batch_size = batch_size\n",
    "    output:\n",
    "        path: 照片路徑 : ./ML_hw2/resize/id\n",
    "        label: 標籤  : int x={0,1,2} array\n",
    "    \"\"\"\n",
    "    path = []\n",
    "    label = []\n",
    "    slice_csv = re.sub('學生的', \"\" ,folder.split('/')[-2] ) #提取training_data或test_data\n",
    "    csv_path = f'{folder}{slice_csv}.csv'\n",
    "    resize_folder = f'{folder}resize/'\n",
    "    if not os.path.isdir(resize_folder):\n",
    "        os.makedirs(resize_folder)\n",
    "    with open(csv_path, 'r', encoding='utf8') as f:        \n",
    "        f.readline()\n",
    "        for line in tqdm(f):\n",
    "            clean_line = line.replace('\\n', '').replace('\\ufeff', '').split(',')\n",
    "            # [id, light, ground_truth, grade]\n",
    "            curr_img_path = f'{folder}{clean_line[1]}/{clean_line[0]}'\n",
    "            new_img_path = f'{resize_folder}{clean_line[0]}'\n",
    "            if not os.path.isfile(curr_img_path):\n",
    "                print(f'No file for path : {curr_img_path}')\n",
    "                continue\n",
    "            #將未處理照片存入新資料夾位置：./ML_hw2/resize/\n",
    "            if not os.path.isfile(new_img_path):\n",
    "                img = cv2.imread(curr_img_path, cv2.IMREAD_COLOR)\n",
    "                img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "                cv2.imwrite(new_img_path, img)\n",
    "            path.append(new_img_path)\n",
    "            label.append(int(clean_line[3])-1)\n",
    "\n",
    "    print('data size: ')\n",
    "    print(len(path), len(label))\n",
    "    count = np.zeros(3)\n",
    "    for check in label:\n",
    "        count[int(check)] += 1\n",
    "    print('(1)：'+str(count[0])+' '+str(count[0]/len(label)))\n",
    "    print('(2)：'+str(count[1])+' '+str(count[1]/len(label)))\n",
    "    print('(3)：'+str(count[2])+' '+str(count[2]/len(label)))\n",
    "\n",
    "    print()\n",
    "    return path, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_prepare(folder='./ML_hw2/學生的training_data/', batch_size=8):\n",
    "    \"\"\"\n",
    "    intro:\n",
    "        使用load_nail_csv準備照片\n",
    "        Dataset轉為dataset型式\n",
    "        切 train, validation set , DataLoader存入\n",
    "    aug:\n",
    "        folder = 讀入資料之目的資料夾\n",
    "        batch_size = batch_size\n",
    "    output:\n",
    "        train_dataloader, valid_dataloader\n",
    "    \"\"\"\n",
    "\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        #torchvision.transforms.Resize((224,224)),\n",
    "        torchvision.transforms.RandomHorizontalFlip(p = 0.5),\n",
    "        torchvision.transforms.RandomRotation(15, resample=PIL.Image.BILINEAR),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        ])\n",
    "\n",
    "    path, label = load_nail_csv(folder)\n",
    "    augment_dataset = Dataset(path, label, transform)\n",
    "    \n",
    "    #切分70%當作訓練集、30%當作驗證集\n",
    "    train_size = int(0.7 * len(augment_dataset))\n",
    "    valid_size = len(augment_dataset) - train_size\n",
    "    train_data, valid_data = torch.utils.data.random_split(augment_dataset, [train_size, valid_size])\n",
    "    \n",
    "    train_dataloader = DataLoader( train_data , batch_size=batch_size, shuffle=True)\n",
    "    valid_dataloader = DataLoader( valid_data , batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return train_dataloader, valid_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,name,n_epochs,train_loader,valid_loader,optimizer,criterion,batch_size,patience):\n",
    "    \"\"\"\n",
    "    intro:\n",
    "        每次epoch都 train the model , validate the model\n",
    "        並計算Early Stopping\n",
    "        印出 train_loss , train_acc , val_loss , val_acc\n",
    "        回傳 model\n",
    "    aug:\n",
    "        model,n_epochs,train_loader,valid_loader,optimizer,criterion,batch_size\n",
    "    output:\n",
    "        model\n",
    "    \"\"\"\n",
    "    if os.path.isfile(f'./hw2_classification_weight_{name}.pt'):\n",
    "        print(f'keep finetune{name}')\n",
    "        model = torch.load(f'./hw2_classification_weight_{name}.pt')\n",
    "    \n",
    "    best_train_loss = 100\n",
    "    best_train_acc = 0\n",
    "    best_val_loss = 100\n",
    "    best_val_acc = 0\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    else:\n",
    "        print('no gpu use')\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # keep track of training and validation loss\n",
    "        train_loss,valid_loss = 0.0,0.0\n",
    "        train_losses,valid_losses=[],[]\n",
    "        train_correct,val_correct,train_total,val_total=0,0,0,0\n",
    "\n",
    "        print('running epoch: {}'.format(epoch))\n",
    "        #############################################################################################################\n",
    "        #                                              train the model                                              #\n",
    "        #############################################################################################################\n",
    "        model.train()\n",
    "        for data, target in train_loader:\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            if torch.cuda.is_available():#train_on_gpu\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            else:\n",
    "                print('1')\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            #calculate accuracy\n",
    "            pred = output.data.max(dim = 1, keepdim = True)[1]\n",
    "            train_correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "            train_total += data.size(0)\n",
    "            \n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update training loss\n",
    "            train_losses.append(loss.item()*data.size(0))\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        #############################################################################################################\n",
    "        #                                            validate the model                                             #\n",
    "        #############################################################################################################\n",
    "        model.eval()\n",
    "        for data, target in valid_loader:\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            if torch.cuda.is_available():#train_on_gpu\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "                \n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss =criterion(output, target)\n",
    "            #calculate accuracy\n",
    "            pred = output.data.max(dim = 1, keepdim = True)[1]\n",
    "            val_correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "            val_total += data.size(0)\n",
    "            # update validation loss\n",
    "            valid_losses.append(loss.item()*data.size(0))\n",
    "        \n",
    "        \n",
    "        #############################################################################################################\n",
    "        #                                        print train/val epoch result                                       #\n",
    "        #############################################################################################################\n",
    "        # calculate average losses\n",
    "        train_loss=np.average(train_losses)\n",
    "        valid_loss=np.average(valid_losses)\n",
    "        # calculate average accuracy\n",
    "        train_acc=train_correct/train_total\n",
    "        valid_acc=val_correct/val_total\n",
    "        print(f'\\tTraining Loss: {train_loss:.3f} \\tValidation Loss: {valid_loss:.3f}')\n",
    "        print(f'\\tTraining Accuracy: {train_acc:.3f} \\tValidation Accuracy: {valid_acc:.3f}')\n",
    "        \n",
    "        #############################################################################################################\n",
    "        #                                              Early Stopping                                               #\n",
    "        #############################################################################################################\n",
    "        if valid_loss > best_val_loss:\n",
    "            trigger_times += 1\n",
    "            print(f'trigger times: {trigger_times}\\n')\n",
    "            if trigger_times > patience:\n",
    "                print(f'Early stopping at trigger times: {trigger_times}')\n",
    "                print(f'\\tLeast Training Loss: {best_train_loss:.4f} \\nLeast Validation Loss: {best_val_loss:.4f}')\n",
    "                print(f'\\tBest Training Accuracy: {best_train_acc:.4f} \\nBest Validation Accuracy: {best_val_acc:.4f}')\n",
    "                break\n",
    "        else:\n",
    "            trigger_times = 0\n",
    "            torch.save(model, f'./hw2_classification_weight_{name}.pt')\n",
    "            best_train_loss = train_loss\n",
    "            best_train_acc = train_acc\n",
    "            best_val_loss = valid_loss\n",
    "            best_val_acc = valid_acc\n",
    "            \n",
    "    model = torch.load(f'./hw2_classification_weight_{name}.pt')    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_result(model): \n",
    "    \"\"\"\n",
    "    intro:\n",
    "        讀取'./ML_hw2/學生的testing_data/'\n",
    "        並將照片處理，拿原本模型預測後輸出文件\n",
    "    aug:\n",
    "        model\n",
    "    result:\n",
    "        ./HW2_E24056954.csv\n",
    "    \"\"\"\n",
    "    #############################################################################################################\n",
    "    #                                   loading and resize testing picture                                      #\n",
    "    #############################################################################################################\n",
    "    testing_path = []\n",
    "    testing_write = []\n",
    "    folder = './ML_hw2/學生的testing_data/'\n",
    "    slice_csv = 'testing_data'#提取testing_data\n",
    "    csv_path = f'{folder}{slice_csv}.csv'\n",
    "    resize_folder = f'{folder}resize/'\n",
    "    if not os.path.isdir(resize_folder):\n",
    "        os.makedirs(resize_folder)\n",
    "    with open(csv_path, 'r', encoding='utf8') as f:   \n",
    "        testing_write.append(f.readline())\n",
    "        for line in f:\n",
    "            clean_line = line.replace('\\n', '').replace('\\ufeff', '').split(',')\n",
    "            # [id, light, ground_truth, grade]\n",
    "            testing_write.append(clean_line)\n",
    "            curr_img_path = f'{folder}{slice_csv}/{clean_line[0]}'\n",
    "            new_img_path = f'{resize_folder}{clean_line[0]}'\n",
    "            if not os.path.isfile(curr_img_path):\n",
    "                print(curr_img_path)\n",
    "                print('catch')\n",
    "                continue\n",
    "            if not os.path.isfile(new_img_path):\n",
    "                img = cv2.imread(curr_img_path, cv2.IMREAD_COLOR)\n",
    "                img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "                cv2.imwrite(new_img_path, img)\n",
    "            testing_path.append(new_img_path)\n",
    "    print('data size: ')\n",
    "    print(f'testing數量：{len(testing_path)}')\n",
    "    \n",
    "    #############################################################################################################\n",
    "    #                                   use hypothesis model predict testing set                                #\n",
    "    #############################################################################################################\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        ])\n",
    "    model.eval()\n",
    "    pred_label=[]\n",
    "    for path in tqdm(testing_path):\n",
    "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "        img = transform(img).cuda()\n",
    "        img = img.unsqueeze(0)\n",
    "        with torch.no_grad(): \n",
    "            output=model(img)\n",
    "        pred = output.data.max(dim = 1, keepdim = True)[1]\n",
    "        pred_label.append(int(pred))\n",
    "        print(f'{path} / {int(pred)}')\n",
    "    #############################################################################################################\n",
    "    #                                             output require csv                                            #\n",
    "    #############################################################################################################\n",
    "    with open('HW2_E24056954.csv', 'w', encoding='utf8') as wp:\n",
    "        wp.write(testing_write[0])\n",
    "        for pred_label_,testing_write_ in zip(pred_label,testing_write[1:]):\n",
    "            wp.write(f'{testing_write_[0]},{testing_write_[1]},,{pred_label_+1}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try alexnet finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ft_alexnet = models.alexnet(pretrained=True)\n",
    "# num_ftrs = model_ft_alexnet.classifier[6].in_features\n",
    "# model_ft_alexnet.classifier[6] = nn.Linear(num_ftrs,3)\n",
    "# model_ft_alexnet=model_ft_alexnet.to(device)# 放入裝置\n",
    "# print(model_ft_alexnet) # 列印新模型\n",
    "\n",
    "# n_epochs = 100\n",
    "# batch_size = 32\n",
    "# train_dataloader, valid_dataloader = dataloader_prepare(folder='./ML_hw2/學生的training_data/',batch_size = batch_size)\n",
    "# optimizer = torch.optim.Adam([\n",
    "#     {'params':model_ft_alexnet.parameters()}\n",
    "# ], lr=0.00001)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# patience = 3\n",
    "\n",
    "# model_ft_alexnet=train(model_ft_alexnet,'model_ft_wide_resnet50_2',n_epochs,train_dataloader,valid_dataloader,optimizer,criterion, batch_size , patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try wide_resnet50_2 finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft_wide_resnet50_2 = models.wide_resnet50_2(pretrained=True)\n",
    "num_ftrs = model_ft_wide_resnet50_2.fc.in_features\n",
    "model_ft_wide_resnet50_2.fc = nn.Linear(num_ftrs,3)\n",
    "model_ft_wide_resnet50_2=model_ft_wide_resnet50_2.to(device)# 放入裝置\n",
    "print(model_ft_wide_resnet50_2) # 列印新模型\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 32\n",
    "train_dataloader, valid_dataloader = dataloader_prepare(folder='./ML_hw2/學生的training_data/',batch_size = batch_size)\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params':model_ft_wide_resnet50_2.parameters()}\n",
    "], lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "patience = 3\n",
    "\n",
    "model_ft_wide_resnet50_2=train(model_ft_wide_resnet50_2,'model_ft_wide_resnet50_2',n_epochs,train_dataloader,valid_dataloader,optimizer,criterion, batch_size , patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try vgg19 finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ft_vgg19 = models.vgg19(pretrained=True)\n",
    "# num_ftrs = model_ft_vgg19.classifier[6].in_features\n",
    "# model_ft_vgg19.classifier[6] = nn.Linear(num_ftrs,3)\n",
    "# model_ft_vgg19=model_ft_vgg19.to(device)# 放入裝置\n",
    "# print(model_ft_vgg19) # 列印新模型\n",
    "\n",
    "# n_epochs = 100\n",
    "# batch_size = 32\n",
    "# train_dataloader, valid_dataloader = dataloader_prepare(folder='./ML_hw2/學生的training_data/',batch_size = batch_size)\n",
    "# optimizer = torch.optim.Adam([\n",
    "#     {'params':model_ft_vgg19.parameters()}\n",
    "# ], lr=0.0001)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# patience = 3\n",
    "\n",
    "# model_ft_vgg19=train(model_ft_vgg19,'model_ft_vgg19',n_epochs,train_dataloader,valid_dataloader,optimizer,criterion, batch_size , patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print testing data result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'model_ft_wide_resnet50_2'\n",
    "model_ft_wide_resnet50_2 = torch.load(f'./hw2_classification_weight_{name}.pt')  \n",
    "testing_result(model_ft_wide_resnet50_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
